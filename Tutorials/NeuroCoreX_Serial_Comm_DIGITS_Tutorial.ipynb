{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21cd376f-1eb5-4e30-911a-c88e59486b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range of pixels values: 16.0\n",
      "Training samples: (1203, 64) 1203  Test samples: (594, 64) 594\n",
      "loaded spike train:594, (32, 64)\n",
      "Testing the trained network on test data\n",
      "Inference metrics on test set: 392 594 0.6599326599326599\n",
      " n samples: 594\n"
     ]
    }
   ],
   "source": [
    "#Import SNN model's parameters and DIGITS dataset.\n",
    "#Requires installation of Superneuromat. \n",
    "# Use pip install superneuromat.\n",
    "\n",
    "import superneuromat as snm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import queue\n",
    "import json \n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# NOTE: Python script to read in the trained model from pickle file and the spike trains \n",
    "# Simualte the network with spike trains and measure accuracy:\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "digits = load_digits()\n",
    "\n",
    "data = digits.data\n",
    "digit_labels = digits.target\n",
    "labels = np.unique(digits.target)\n",
    "n_labels = len(labels)\n",
    "\n",
    "n_inputs = digits.data.shape[-1]\n",
    "\n",
    "print('Range of pixels values:',np.max(data))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, digit_labels, test_size=0.33, random_state=42)\n",
    "print('Training samples:', X_train.shape, len(y_train), ' Test samples:', X_test.shape, len(y_test))\n",
    "\n",
    "\n",
    "# read the pickle file:\n",
    "filename = \"digits_network.pkl\" \n",
    "with open(filename, \"rb\") as file:\n",
    "    infer_model = pickle.load(file)\n",
    "    digits_test_spike_trains = pickle.load(file)\n",
    "\n",
    "print(f\"loaded spike train:{len(digits_test_spike_trains)}, {digits_test_spike_trains[0].shape}\")\n",
    "\n",
    "\n",
    "#Apply the input to the infer_model:\n",
    "print('Testing the trained network on test data')\n",
    "\n",
    "# Apply the data:\n",
    "sample_count = 0           #sample count parsed so far\n",
    "accuracy = 0\n",
    "\n",
    "for sample_spikes in digits_test_spike_trains:    # across all test samples\n",
    "\n",
    "    count = 0\n",
    "    infer_model.setup()\n",
    "    infer_model.input_spikes = {}\n",
    "    infer_model.spike_train = []\n",
    "\n",
    "    timestep = 0\n",
    "    for all_spikes in sample_spikes:\n",
    "        for n, v in enumerate(all_spikes):\n",
    "            infer_model.add_spike(timestep, n+n_labels, int(v))\n",
    "        timestep+=1\n",
    "\n",
    "    infer_model.simulate(32)\n",
    "    #######################################\n",
    "    \n",
    "    test_output = infer_model.spike_train\n",
    "    test_output = np.array(test_output)\n",
    "    input_spike_count = np.sum(test_output[:,10:],0)\n",
    "    input_spike_count = np.reshape(input_spike_count,(8,8))\n",
    "\n",
    "    input_spikes = test_output[:,10:]\n",
    "    input_spikes_t =input_spikes.transpose()\n",
    "\n",
    "    # check if the lable neuron has the highest spikes:\n",
    "    spike_sum = np.sum(test_output[:,:10],0)\n",
    "    target_spikes_observed = spike_sum[y_test[sample_count]]\n",
    "    max_spikes_id = np.argmax(spike_sum)\n",
    "    if max_spikes_id == y_test[sample_count]:\n",
    "        accuracy+=1\n",
    "        \n",
    "    sample_count +=1\n",
    "\n",
    "print('Inference metrics on test set:',accuracy, sample_count, accuracy/sample_count)\n",
    "print(' n samples:', len(y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "915bee3f-4921-42cd-a9f2-00cd70af3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import threading\n",
    "import queue\n",
    "import numpy as np\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "SERIAL_PORT = 'COM4'       # Replace with your actual port\n",
    "BAUD_RATE = 1000000 #1000000\n",
    "N = 96#20      \n",
    "N_actual=N-6\n",
    "\n",
    "# === FLAGS ===\n",
    "flag_AA_en = 1\n",
    "flag_FF_en = 1\n",
    "flag_Thr_en = 1\n",
    "flag_NIST_en = 1\n",
    "flag_READ_en = 1\n",
    "flag_DEBUG_en=1\n",
    "flag_STDP_en=1\n",
    "\n",
    "flag_Recieving_SPIKES=1\n",
    "\n",
    "flag_DUMMY_DATA=0\n",
    "flag_DIGITS_DATA=1\n",
    "flag_plot_raster=0\n",
    "\n",
    "num_raster=11 #Number of neurons to plot on the raster plot out of N. DIGITS needs 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c3a95f-245c-42a3-aa08-149beb4d6041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Weight_AA\n",
    "scaling_factor_FPGA=1\n",
    "\n",
    "# if flag_DIGITS_DATA: #No all to all connected weights\n",
    "#     weights_AA=np.zeros((N_actual,N_actual))#infer_model._weights\n",
    "#     # weights_AA=weights_AA.T\n",
    "#     print(\"The shape of weight matrix is:\", weights_AA.shape)\n",
    "#     print(\"For unscaled weights, Max weight:\", np.max(weights_AA), \"and Min weight:\",np.min(weights_AA) )\n",
    "\n",
    "if flag_DUMMY_DATA or flag_DIGITS_DATA: #Program as per need\n",
    "    start_row = 6\n",
    "    start_col = 5\n",
    "    diag_size = N_actual  # 14x14 diagonal submatrix\n",
    "    \n",
    "    # # Precompute diagonal indices in flattened (row-major) space\n",
    "    # diag_indices_AA = [(start_row + i) * N + (start_col + i) for i in range(diag_size)]\n",
    "    \n",
    "    # print(diag_indices_AA)\n",
    "    y=0\n",
    "    weights_AA = np.ones((N_actual, N_actual))*y\n",
    "    # Set the value\n",
    "    x = 0  # (or whatever value you want)    \n",
    "    \n",
    "    for start_col in range(0, N_actual, N_actual):\n",
    "        end_col = start_col + N_actual\n",
    "        if end_col <= N_actual:\n",
    "            for i in range(N_actual):\n",
    "                weights_AA[i, start_col + i] = x\n",
    "\n",
    "# Scale first\n",
    "weights_AA_scaled = weights_AA*scaling_factor_FPGA\n",
    "#Clip to int8 range\n",
    "weights_AA_scaled = np.clip(weights_AA_scaled, -128, 127)\n",
    "padded_matrix_AA = np.zeros((N, N), dtype=np.int8)\n",
    "padded_matrix_AA[6:, 5:-1] = weights_AA_scaled\n",
    "\n",
    "# print(weights_AA_scaled)\n",
    "\n",
    "# print(\"The shape of the padded weight matrix is:\",padded_matrix_AA.shape)\n",
    "# print(padded_matrix_AA[:,11])\n",
    "\n",
    "flat_weights_AA=padded_matrix_AA.flatten()\n",
    "\n",
    "# print(\"Datatype of weights are\", flat_weights_AA.dtype)\n",
    "# print(\"Max weight:\", np.max(flat_weights_AA), \"and Min weight:\",np.min(flat_weights_AA) )\n",
    "# print(np.where(flat_weights_AA!=0))\n",
    "# print(weights_AA_scaled.shape)\n",
    "# print(weights_AA_scaled[:,0:5])\n",
    "# print(padded_matrix_AA[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "202364af-1561-4a05-88bd-552ff839d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up Inputs_Weights refered to as W_FF\n",
    "start_row_FPGA = 6\n",
    "start_col_FPGA = 2\n",
    "\n",
    "if flag_DIGITS_DATA:\n",
    "    weights_FF=infer_model._weights[-64:, :10]\n",
    "    # print(weights_FF)\n",
    "    weights_FF=weights_FF.T\n",
    "    # print(weights_FF.shape)\n",
    "    # print(np.max(weights_FF))\n",
    "\n",
    "if flag_DUMMY_DATA:\n",
    "    start_row = 6\n",
    "    start_col = 2\n",
    "    diag_size = N_actual  # 90x90 diagonal submatrix\n",
    "        # # Precompute diagonal indices in flattened (row-major) space\n",
    "    diag_indices_FF = [(start_row + i) * N + (start_col + i) for i in range(diag_size)]\n",
    "    weights_FF = np.zeros((10, 64))\n",
    "    x = 110  # (or whatever value you want)    \n",
    "    \n",
    "    for start_col in range(0, 64, 10):\n",
    "        end_col = start_col + 10\n",
    "        if end_col <= 64:\n",
    "            for i in range(10):\n",
    "                weights_FF[i, start_col + i] = x\n",
    "    # print(\"The shape of weight matrix FF is:\", weights_FF.shape)\n",
    "\n",
    "# Scale first\n",
    "weights_FF_scaled = weights_FF\n",
    "#Clip to int8 range\n",
    "weights_FF_scaled = np.clip(weights_FF_scaled, -128, 127)\n",
    "padded_matrix_FF = np.zeros((N, N), dtype=np.int8)\n",
    "padded_matrix_FF[6:-80, 2:-30] = weights_FF_scaled\n",
    "\n",
    "\n",
    "\n",
    "# print(\"The shape of the padded weight matrix FF is:\",padded_matrix_FF.shape)\n",
    "# print(padded_matrix_FF[:,11])\n",
    "\n",
    "flat_weights_FF=padded_matrix_FF.flatten()\n",
    "# flat_weights_FF=flat_weights_FF*10#[elem*10 for elem in flat_weights_FF]\n",
    "\n",
    "# print(\"Datatype of weights FF are\", flat_weights_FF.dtype)\n",
    "# print(\"Max weight:\", np.max(flat_weights_FF), \"and Min weight:\",np.min(flat_weights_FF) )\n",
    "diag_check=np.where(flat_weights_FF!=0)\n",
    "# print(diag_check)#tuple\n",
    "# print(diag_indices_FF)#list\n",
    "# if diag_check==diag_indices_FF:\n",
    "#     print(\"Only diagonal elements have weights\")\n",
    "# print(weights_FF_scaled.shape)\n",
    "# print(weights_FF_scaled[:,0:5])\n",
    "# print(padded_matrix_FF[:,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3b8afba-5ec6-4b99-9ba8-6e4bc33a1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read Neuron Parameters for the neurons on the FPGA\n",
    "Leak = infer_model._neuron_leaks [0:10]\n",
    "Ref_period=infer_model._neuron_refractory_periods_original[0:10]\n",
    "Threshold= infer_model._neuron_thresholds[0:10]\n",
    "Threshold_scaled=Threshold*scaling_factor_FPGA\n",
    "# print(\"The datatype of the read parameters are:\", Threshold.dtype)\n",
    "# Leak=np.zeros(10)\n",
    "Leak = np.concatenate((np.zeros(4, dtype=Leak.dtype), Leak, np.zeros(82, dtype=Leak.dtype)))\n",
    "Ref_period = np.concatenate((np.zeros(4, dtype=Ref_period.dtype), Ref_period, np.zeros(82, dtype=Ref_period.dtype)))\n",
    "Threshold_scaled = np.concatenate((np.ones(4, dtype=Threshold.dtype)*120, Threshold_scaled, np.ones(82, dtype=Threshold.dtype)*120))\n",
    "# print(\"The Ref. period of\", len(Ref_period), \"neurons are:\", Ref_period)\n",
    "# print(\"The Leak of\", len(Leak), \"neurons are:\", Leak)\n",
    "# print(\"The Threshold of\", len(Threshold_scaled), \"neurons are:\", Threshold_scaled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36abd79c-0ed3-458d-9a85-602ccaa216a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only needed for Debugging\n",
    "def send_debug_params(a):\n",
    "    if flag_DEBUG_en:\n",
    "        serialPort.write(b'\\x40')\n",
    "        print(\"Debug params\")\n",
    "        time.sleep(0.01)  \n",
    "        serialPort.write(b'\\x00')  # I_BIAS\n",
    "        time.sleep(0.001)\n",
    "        serialPort.write(b'\\x00')  # \n",
    "        time.sleep(0.001)\n",
    "        serialPort.write(b'\\x00')  # \n",
    "        time.sleep(0.001)\n",
    "        \n",
    "        serialPort.write(bytes([int(a)]))# N_debug_int\n",
    "        # serialPort.write(b'\\x01')  # N_debug_int\n",
    "        time.sleep(0.001)\n",
    "        serialPort.write(b'\\x00')  # \n",
    "        time.sleep(0.001)\n",
    "        serialPort.write(b'\\x00')  # \n",
    "        time.sleep(0.001)\n",
    "        print(\"sent n-debug#\", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abdfc99c-3512-424d-ada0-cea80f37adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to recieve spikes data from the FPGA\n",
    "def recieve_data_from_FPGA(result_queue):\n",
    "    global receiver_stop_flag\n",
    "    if flag_Recieving_SPIKES==1:\n",
    "        bit_stream = []\n",
    "        bytess = []\n",
    "        # print(\"Start recieving\")\n",
    "        # Step 1: Wait for start marker 0xFF\n",
    "        start_marker_detected = False\n",
    "        while not start_marker_detected:\n",
    "            if serialPort.in_waiting:\n",
    "                byte = serialPort.read()\n",
    "                if byte[0] == 0xFF:\n",
    "                    start_marker_detected = True\n",
    "                    print(\"Start marker detected!\")\n",
    "        \n",
    "        # while receiver_stop_flag == 0:\n",
    "        # while len(bit_stream)<=2880:\n",
    "        # expected_bytes = 360\n",
    "        # while len(bytess) < expected_bytes:\n",
    "        while receiver_stop_flag == 0:\n",
    "            if serialPort.in_waiting:\n",
    "                byte = serialPort.read()\n",
    "                bytess.append(byte)\n",
    "                # byte_val = byte[0]\n",
    "                # for i in range(8):  # LSB-first\n",
    "                #     bit_stream.append((byte_val >> i) & 0x01)\n",
    "        # print(f\"Received {len(bytess)} bytes\")\n",
    "\n",
    "        # Step 3: Unpack bytes into bits\n",
    "        for byte in bytess:\n",
    "            byte_val = byte[0]\n",
    "            for i in range(8):  # LSB first\n",
    "                bit_stream.append((byte_val >> i) & 0x01)\n",
    "        \n",
    "        # print(f\"Total bits received: {len(bit_stream)} bits\")\n",
    "        serialPort.close()\n",
    "        # print(len(bytess))\n",
    "        \n",
    "        # print(\"Start decoding with overlap-aware unpacking\")\n",
    "        \n",
    "        # Reconstruct 14-bit frames accounting for overlap\n",
    "        # N_actual = 14\n",
    "        spike_frames = []\n",
    "        bit_buffer = []\n",
    "        \n",
    "        for bit in bit_stream:\n",
    "            bit_buffer.append(bit)\n",
    "            if len(bit_buffer) >= N_actual:\n",
    "                frame = bit_buffer[:N_actual]\n",
    "                spike_frames.append(frame)\n",
    "                bit_buffer = bit_buffer[N_actual:]  # remove used bits, keep overlap\n",
    "        \n",
    "        # Convert to NumPy array\n",
    "        spike_array = np.array(spike_frames).T  # shape: (96, T)\n",
    "        \n",
    "        # print(f\"Spike matrix shape: {spike_array.shape}\")\n",
    "        \n",
    "        # Plot raster\n",
    "        if flag_plot_raster:\n",
    "            plt.figure(figsize=(10, 16))\n",
    "            for neuron_idx in range(N_actual):\n",
    "                if neuron_idx<num_raster:\n",
    "                    spike_times = np.where(spike_array[neuron_idx] == 1)[0]\n",
    "                    plt.vlines(spike_times, neuron_idx + 0.5, neuron_idx + 1.5)\n",
    "            \n",
    "            plt.xlabel('Timestep')\n",
    "            plt.ylabel('Neuron Index')\n",
    "            # plt.title('Spike Raster Plot (Overlap-aware)')\n",
    "            # plt.yticks(range(1, N_actual + 1))\n",
    "            plt.yticks(range(1, num_raster + 1))\n",
    "            plt.grid(True, linestyle='--', alpha=0.3)\n",
    "            \n",
    "            # plt.tight_layout()\n",
    "            plt.show()              \n",
    "        result_queue.put(spike_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e31e80f1-1bd1-48d2-905d-521551eb70b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SEND Weights, neuron, synapse, and learning parameters ===\n",
    "def send_weights_and_params():\n",
    "    if flag_AA_en:\n",
    "        serialPort.write(b'\\x10')  # AA command\n",
    "        print(\"Sending AA\")\n",
    "        time.sleep(0.01)\n",
    "        weights_bytes_AA = bytes(flat_weights_AA)\n",
    "        serialPort.write(weights_bytes_AA)                 \n",
    "        \n",
    "        serialPort.write(b'\\x00')\n",
    "        \n",
    "    if flag_FF_en:\n",
    "        serialPort.write(b'\\x00')  # FF command\n",
    "        print(\"Sending FF\")     \n",
    "        weights_bytes_FF = bytes(flat_weights_FF)\n",
    "        serialPort.write(weights_bytes_FF) \n",
    "        \n",
    "        serialPort.write(b'\\x00')\n",
    "\n",
    "    if flag_STDP_en:\n",
    "        serialPort.write(b'\\x60')  # FF command\n",
    "        print(\"Sending STDP enable matrix\")\n",
    "        for byte in uart_packets_AA:\n",
    "            serialPort.write(bytes([byte]))\n",
    "        for byte in uart_packets_FF:\n",
    "            serialPort.write(bytes([byte]))\n",
    "    serialPort.write(b'\\x00')\n",
    "    \n",
    "    if flag_DUMMY_DATA or flag_DIGITS_DATA:\n",
    "        if flag_Thr_en:\n",
    "            serialPort.write(b'\\x20')  # Threshold command\n",
    "            print(\"Sending Thr\")\n",
    "            time.sleep(0.001)\n",
    "            for _ in range(4):\n",
    "                serialPort.write(b'\\xff')  # Threshold value #af\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\xff')  # Threshold value, 06->51%\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x01')  # Threshold value\n",
    "                time.sleep(0.001)\n",
    "            for _ in range(N-6):\n",
    "                serialPort.write(b'\\x00')  # Threshold value #af\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x90')  # Threshold value\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x01')  # Threshold value\n",
    "                time.sleep(0.001)\n",
    "            for _ in range(2):\n",
    "                serialPort.write(b'\\xff')  # Threshold value #af\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\xff')  # Threshold value\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x01')  # Threshold value\n",
    "                time.sleep(0.001)\n",
    "                \n",
    "            print(\"Sending Tref\")\n",
    "            serialPort.write(b'\\x01')  # Scaling factor (b'\\x1f')\n",
    "            time.sleep(0.001)\n",
    "            serialPort.write(b'\\x00')  # Tref value\n",
    "            time.sleep(0.001)\n",
    "            serialPort.write(b'\\x00')  # Tref value\n",
    "            time.sleep(0.001)\n",
    "            for _ in range(N-1):\n",
    "                serialPort.write(b'\\x00')  # Tref value (b'\\x1f')\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x00')  # Tref value\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x00')  # Tref value\n",
    "                time.sleep(0.001)\n",
    "                \n",
    "            print(\"Sending Tau_mem\")\n",
    "            for _ in range(N):\n",
    "                # serialPort.write(bytes([int(0)]))\n",
    "                serialPort.write(b'\\x00')  # Tau_mem value 66\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x00')  # Tau_mem value #04\n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x00')  # Tau_mem value\n",
    "                time.sleep(0.001)\n",
    "            \n",
    "            print(\"Sending STDP_params\")\n",
    "            serialPort.write(b'\\x7f')  # tpre_FF_max value\n",
    "            time.sleep(0.001)\n",
    "            serialPort.write(b'\\x7f')  # tpost_FF_max value\n",
    "            time.sleep(0.001)\n",
    "            serialPort.write(b'\\x00')  # \n",
    "            time.sleep(0.001)\n",
    "            serialPort.write(b'\\x7f')  # tpre__AA_max value\n",
    "            time.sleep(0.001)\n",
    "            serialPort.write(b'\\x7f')  # tpost_AA_max value\n",
    "            time.sleep(0.001)\n",
    "            serialPort.write(b'\\x7f')  # \n",
    "            time.sleep(0.001)             \n",
    "            for _ in range(N-2):\n",
    "                # serialPort.write(bytes([int(0)]))\n",
    "                serialPort.write(b'\\x01')  # delta_w \n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x01')  # \n",
    "                time.sleep(0.001)\n",
    "                serialPort.write(b'\\x00')  # \n",
    "                time.sleep(0.001)           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "374987eb-2817-4058-a932-f041cef0833d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === RUN SIMULATION ===\n",
    "def run_simulation(NA, spike_array):\n",
    "    global receiver_stop_flag\n",
    "    if flag_DUMMY_DATA:\n",
    "        if flag_NIST_en:\n",
    "            # Prepare the big data buffer\n",
    "            send_buffer = bytearray()\n",
    "            dt=5\n",
    "            for _ in range(1):\n",
    "                # for n_address in range(NA,Y+1,1):\n",
    "                for n_address in range(2,5,1):\n",
    "                    # print(xxx,dt, type(xxx), type(dt))\n",
    "                    send_buffer.append(dt)       # relative time\n",
    "                    send_buffer.append(n_address)   # neuron index\n",
    "                    send_buffer.append(0x00)      # padding\n",
    "            # Append FF markers (stop signal)\n",
    "            send_buffer.extend([0xFF, 0xFF, 0xFF])\n",
    "            serialPort.write(b'\\x30')  # Start NIST command\n",
    "            print(\"Sending Spike Data\")\n",
    "            serialPort.write(send_buffer)            \n",
    "            time.sleep(0.1)\n",
    "            receiver_stop_flag=1\n",
    "            # print(\"Done Spike Data\", receiver_stop_flag)\n",
    "\n",
    "    if flag_DIGITS_DATA:\n",
    "        if flag_NIST_en:\n",
    "\n",
    "            # print(\"Sending Spike Data\")\n",
    "            times, neurons = np.nonzero(spike_array)\n",
    "            neuron_indices = (neurons.astype(np.uint8)+ 2).astype(np.uint8) #neurons.tolist()\n",
    "            time_indices = times.astype(np.uint8) #times.tolist()\n",
    "            relative_time_diffs = [time_indices[0]] + [t2 - t1 for t1, t2 in zip(time_indices[:-1], time_indices[1:])]\n",
    "            relative_time_diffs = [0 if val == 1 else val for val in relative_time_diffs]\n",
    "            # relative_time_diffs = np.array(relative_time_diffs, dtype=np.uint8)\n",
    "            relative_time_diffs = np.clip(relative_time_diffs, 0, 255).astype(np.uint8)\n",
    "        \n",
    "            # Prepare the big data buffer\n",
    "            send_buffer = bytearray()\n",
    "            for dt, neuron in zip(relative_time_diffs, neuron_indices):\n",
    "                send_buffer.append(dt)       # relative time\n",
    "                send_buffer.append(neuron)   # neuron index\n",
    "                send_buffer.append(0x00)      # padding\n",
    "\n",
    "            # Append FF markers (stop signal)\n",
    "            send_buffer.extend([0xFF, 0xFF, 0xFF])\n",
    "            # Start sending data\n",
    "            serialPort.write(b'\\x30')  # Start NIST command\n",
    "            serialPort.write(send_buffer)            \n",
    "            time.sleep(1)\n",
    "            # print(\"Sent STOP, waiting 1 sec\")\n",
    "            receiver_stop_flag= 1\n",
    "            # print(\"Sent STOP flag\",receiver_stop_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74ad6188-628b-4d3b-bd91-29d75004be0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup bits STDP enable filter, if all zeros, STDP is disabled for all synapses\n",
    "#DIGITS doesn't need STDP hence we set the flags to 0\n",
    "\n",
    "# stdp_en_FF=np.zeros((N_actual,N_actual))\n",
    "# Step 1: Extract and convert to binary (if needed)\n",
    "# matrix = model._stdp_enabled_synapses  # Assuming it's a 2D NumPy array or similar\n",
    "# binary_matrix = (np.array(matrix) > 0).astype(np.uint8)  # Ensure values are 0 or 1\n",
    "# print(binary_matrix.shape, binary_matrix.dtype)\n",
    "# stdp_en_AA=binary_matrix\n",
    "# stdp_en_AA=np.zeros((N_actual,N_actual))\n",
    "\n",
    "padded_stdp_enable_matrix_FF=np.zeros((N,N))\n",
    "# padded_stdp_enable_matrix_FF[6:-80, 2:-30]=stdp_en_FF\n",
    "\n",
    "padded_stdp_enable_matrix_AA=np.zeros((N,N))\n",
    "# padded_stdp_enable_matrix_AA[6:, 5:-1]=stdp_en_AA\n",
    "\n",
    "# print(padded_stdp_enable_matrix_AA.shape, padded_stdp_enable_matrix_AA.dtype)\n",
    "\n",
    "# Assume model._stdp_enabled_synapses is your matrix (N x N)\n",
    "synapse_matrix_FF = padded_stdp_enable_matrix_FF#model._stdp_enabled_synapses\n",
    "synapse_matrix_AA = padded_stdp_enable_matrix_AA#model._stdp_enabled_synapses\n",
    "\n",
    "# Step 1: Flatten in row-major order (default in NumPy)\n",
    "flat_bits_FF = synapse_matrix_FF.flatten().astype(np.uint8)\n",
    "flat_bits_AA = synapse_matrix_AA.flatten().astype(np.uint8)\n",
    "# print(flat_bits_AA.dtype)\n",
    "# Step 2: Pad to make total bit count divisible by 8\n",
    "padding = (8 - (flat_bits_FF.size % 8)) % 8\n",
    "if padding > 0:\n",
    "    # print(\"CHECK THIS\")\n",
    "    flat_bits_FF = np.concatenate([flat_bits_FF, np.zeros(padding, dtype=np.uint8)])\n",
    "    flat_bits_AA = np.concatenate([flat_bits_AA, np.zeros(padding, dtype=np.uint8)])\n",
    "\n",
    "# Step 3: Reshape to (num_bytes, 8)\n",
    "bit_groups_FF = flat_bits_FF.reshape(-1, 8)\n",
    "bit_groups_AA = flat_bits_AA.reshape(-1, 8)\n",
    "\n",
    "# Step 4: Pack LSB-first\n",
    "bytes_list_FF = []\n",
    "bytes_list_AA = []\n",
    "for bits in bit_groups_FF:\n",
    "    byte = 0\n",
    "    for i, bit in enumerate(bits):  # LSB-first: bit[0] goes to b0\n",
    "        byte |= (bit << i)\n",
    "    bytes_list_FF.append(byte)\n",
    "\n",
    "for bits in bit_groups_AA:\n",
    "    byte = 0\n",
    "    for i, bit in enumerate(bits):  # LSB-first: bit[0] goes to b0\n",
    "        byte |= (bit << i)\n",
    "    bytes_list_AA.append(byte)\n",
    "\n",
    "# Final byte array\n",
    "uart_packets_FF = np.array(bytes_list_FF, dtype=np.uint8)\n",
    "uart_packets_AA = np.array(bytes_list_AA, dtype=np.uint8)\n",
    "\n",
    "# print(uart_packets_AA)\n",
    "# print(flat_bits_AA.shape, uart_packets_AA.dtype)\n",
    "# print(np.where(flat_bits_AA==1))\n",
    "# print(f\"Total bytes to send: {len(uart_packets_AA)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8cd68f2e-1acf-46b4-8303-d601c129803a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug params\n",
      "sent n-debug# 1\n",
      "Sending AA\n",
      "Sending FF\n",
      "Sending STDP enable matrix\n",
      "Sending Thr\n",
      "Sending Tref\n",
      "Sending Tau_mem\n",
      "Sending STDP_params\n",
      "Test image 0\n",
      "Start marker detected!\n",
      "Test image 1\n",
      "Start marker detected!\n",
      "Test image 2\n",
      "Start marker detected!\n",
      "Test image 3\n",
      "Start marker detected!\n",
      "Test image 4\n",
      "Start marker detected!\n",
      "Test image 5\n",
      "Start marker detected!\n",
      "Test image 6\n",
      "Start marker detected!\n",
      "Test image 7\n",
      "Start marker detected!\n",
      "Test image 8\n",
      "Start marker detected!\n",
      "Test image 9\n",
      "Start marker detected!\n",
      "Test image 10\n",
      "Start marker detected!\n",
      "11\n",
      "(90, 567) [21 27 24 20 26 24 40 20 30 22]\n",
      "(90, 689) [28 30 31 36 28 36 31 30 35 34]\n",
      "(90, 535) [20 26 28 35 17 28 27 22 30 26]\n",
      "(90, 559) [20 26 22 22 25 27 24 28 27 21]\n",
      "(90, 595) [22 30 33 29 19 27 33 20 31 21]\n",
      "(90, 639) [21 32 34 24 24 32 33 19 32 21]\n",
      "(90, 635) [25 32 30 27 28 37 32 29 32 21]\n",
      "(90, 515) [21 27 29 28 22 27 24 28 29 23]\n",
      "(90, 557) [19 26 26 23 24 34 26 25 26 17]\n",
      "(90, 627) [22 29 35 31 24 28 27 28 31 20]\n",
      "(90, 555) [19 38 32 31 27 26 26 31 33 22]\n",
      "Inference metrics on FPGA test set: 9 11 Accuracy: 0.8181818181818182\n",
      "Total samples flagged with extra spikes: 0\n",
      "Indices with extra spikes: []\n"
     ]
    }
   ],
   "source": [
    "spike_array_list=[]\n",
    "flag_STDP_en=1\n",
    "serialPort = serial.Serial(SERIAL_PORT, BAUD_RATE)\n",
    "serialPort.reset_input_buffer()\n",
    "serialPort.reset_output_buffer()\n",
    "send_debug_params(1)\n",
    "send_weights_and_params()\n",
    "flag_plot_raster=0\n",
    "\n",
    "global receiver_stop_flag\n",
    "\n",
    "for j in range(len(digits_test_spike_trains)):\n",
    "    if j<11:\n",
    "\n",
    "        if j>0:\n",
    "            serialPort = serial.Serial(SERIAL_PORT, BAUD_RATE)\n",
    "        ####Input test spike trains from DIGITS##################################\n",
    "        spike_array=np.array(digits_test_spike_trains[j])\n",
    "        N_debug=int(j)\n",
    "        NA=2\n",
    "        print(\"Test image\",j)\n",
    "        # print(\"Testing Neuron\", NA)\n",
    "        result_queue = queue.Queue()\n",
    "        receiver_stop_flag=0\n",
    "        \n",
    "        # Flush buffers before receiving\n",
    "        serialPort.flushInput()\n",
    "        serialPort.reset_input_buffer()\n",
    "        serialPort.reset_output_buffer()\n",
    "        thread1 = threading.Thread(target=recieve_data_from_FPGA, args=(result_queue,))\n",
    "        thread1.start()\n",
    "        # time.sleep(2)\n",
    "        # print(\"Now starting\")\n",
    "        run_simulation(NA, spike_array) #First two arguments unused\n",
    "        received_data = result_queue.get()\n",
    "        thread1.join()\n",
    "        spike_array_list.append(received_data)\n",
    "\n",
    "\n",
    "\n",
    "sample_count = 0\n",
    "accuracy = 0\n",
    "error_flagged_samples = []  # To store indices where extra neuron spikes\n",
    "predicted_labels_all=[]\n",
    "print(len(spike_array_list))\n",
    "for idx, spike_array in enumerate(spike_array_list):\n",
    "    # spike_array shape: (90, N)\n",
    "    \n",
    "    # Calculate total spikes for label neurons (0-9)\n",
    "    label_spike_counts = np.sum(spike_array[0:10], axis=1)  # Sum over time, per neuron (0-9)\n",
    "    print(spike_array.shape, label_spike_counts)\n",
    "    # Predict based on maximum spiking neuron\n",
    "    predicted_label = np.argmax(label_spike_counts)\n",
    "    predicted_labels_all.append(predicted_label)\n",
    "    \n",
    "    # Check accuracy\n",
    "    if predicted_label == y_test[idx]:\n",
    "        accuracy += 1\n",
    "    \n",
    "    # Check if any of neurons 10 to 95 fired\n",
    "    if np.any(spike_array[10:90, :] > 0):\n",
    "        print(f\"Warning: Extra spikes detected in sample {idx}\")\n",
    "        error_flagged_samples.append(idx)\n",
    "\n",
    "    sample_count += 1\n",
    "\n",
    "print('Inference metrics on FPGA test set:', accuracy, sample_count, \"Accuracy:\", accuracy/sample_count)\n",
    "print('Total samples flagged with extra spikes:', len(error_flagged_samples))\n",
    "print('Indices with extra spikes:', error_flagged_samples)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57b1991-3775-4e1f-81b0-fa2383fab9ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
